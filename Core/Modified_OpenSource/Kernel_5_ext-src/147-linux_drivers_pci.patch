diff -Naur ori_linux/drivers/pci/controller/aspeed_pciecfg.c linux/drivers/pci/controller/aspeed_pciecfg.c
--- ori_linux/drivers/pci/controller/aspeed_pciecfg.c	1970-01-01 08:00:00.000000000 +0800
+++ linux/drivers/pci/controller/aspeed_pciecfg.c	2022-09-06 14:18:22.955746376 +0800
@@ -0,0 +1,122 @@
+// SPDX-License-Identifier: GPL-2.0+
+/*
+ * PCIe host controller driver for ASPEED PCIe Bridge
+ *
+ */
+#include <linux/of_platform.h>
+#include <linux/mfd/syscon.h>
+#include <linux/regmap.h>
+#include <linux/irqdomain.h>
+#include <linux/kernel.h>
+#include <linux/reset.h>
+#include <linux/of.h>
+#include <linux/of_irq.h>
+#include <linux/of_address.h>
+
+struct aspeed_pciecfg {
+	void __iomem *reg;
+	struct regmap *ahbc;
+	struct reset_control *rst;
+	struct reset_control *rc_low_rst;
+	struct reset_control *rc_high_rst;
+};
+
+static const struct of_device_id aspeed_pciecfg_of_match[] = {
+	{ .compatible = "aspeed,ast2600-pciecfg", },
+	{}
+};
+
+#define AHBC_UNLOCK	0xAEED1A03
+static void aspeed_pciecfg_init(struct aspeed_pciecfg *pciecfg)
+{
+	reset_control_assert(pciecfg->rst);
+
+	if (pciecfg->rc_low_rst) {
+		reset_control_deassert(pciecfg->rc_low_rst);
+		reset_control_assert(pciecfg->rc_low_rst);
+	}
+
+	if (pciecfg->rc_high_rst) {
+		reset_control_deassert(pciecfg->rc_high_rst);
+		reset_control_assert(pciecfg->rc_high_rst);
+	}
+
+	mdelay(1);
+	reset_control_deassert(pciecfg->rst);
+
+	//workaround : Send vender define message for avoid when PCIE RESET send unknown message out
+	writel(0x34000000, pciecfg->reg + 0x10);
+	writel(0x0000007f, pciecfg->reg + 0x14);
+	writel(0x00001a03, pciecfg->reg + 0x18);
+	writel(0x00000000, pciecfg->reg + 0x1C);
+
+	regmap_write(pciecfg->ahbc, 0x00, AHBC_UNLOCK);
+	regmap_update_bits(pciecfg->ahbc, 0x8C, BIT(5), BIT(5));
+	regmap_write(pciecfg->ahbc, 0x00, 0x1);
+
+	//ahb to pcie rc
+	writel(0xe0006000, pciecfg->reg + 0x60);
+	writel(0x00000000, pciecfg->reg + 0x64);
+	writel(0xFFFFFFFF, pciecfg->reg + 0x68);
+
+	//PCIe Host Enable
+	writel(BIT(0), pciecfg->reg + 0x00);
+
+}
+
+static int aspeed_pciecfg_probe(struct platform_device *pdev)
+{
+	struct aspeed_pciecfg *pciecfg;
+	struct device *dev = &pdev->dev;
+
+	pciecfg = devm_kzalloc(&pdev->dev, sizeof(*pciecfg), GFP_KERNEL);
+	if (!pciecfg)
+		return -ENOMEM;
+
+	pciecfg->reg = devm_platform_ioremap_resource(pdev, 0);
+	if (IS_ERR(pciecfg->reg))
+		return PTR_ERR(pciecfg->reg);
+
+	pciecfg->rst = devm_reset_control_get_exclusive(&pdev->dev, NULL);
+	if (IS_ERR(pciecfg->rst)) {
+		dev_err(&pdev->dev, "can't get pcie reset\n");
+		return PTR_ERR(pciecfg->rst);
+	}
+
+	if (of_device_is_available(of_parse_phandle(dev->of_node, "aspeed,pcie0", 0))) {
+		pciecfg->rc_low_rst = devm_reset_control_get_shared(&pdev->dev, "rc_low");
+		if (IS_ERR(pciecfg->rc_low_rst)) {
+			dev_info(&pdev->dev, "No RC low reset\n");
+			pciecfg->rc_low_rst = NULL;
+		}
+	} else
+		pciecfg->rc_low_rst = NULL;
+
+
+	if (of_device_is_available(of_parse_phandle(dev->of_node, "aspeed,pcie1", 0))) {
+		pciecfg->rc_high_rst = devm_reset_control_get_shared(&pdev->dev, "rc_high");
+		if (IS_ERR(pciecfg->rc_high_rst)) {
+			dev_info(&pdev->dev, "No RC high reset\n");
+			pciecfg->rc_high_rst = NULL;
+		}
+	} else
+		pciecfg->rc_high_rst = NULL;
+
+	pciecfg->ahbc = syscon_regmap_lookup_by_compatible("aspeed,aspeed-ahbc");
+	if (IS_ERR(pciecfg->ahbc))
+		return IS_ERR(pciecfg->ahbc);
+
+	aspeed_pciecfg_init(pciecfg);
+
+	return 0;
+}
+
+static struct platform_driver aspeed_pciecfg_driver = {
+	.driver = {
+		.name = "aspeed-pciecfg",
+		.suppress_bind_attrs = true,
+		.of_match_table = aspeed_pciecfg_of_match,
+	},
+	.probe = aspeed_pciecfg_probe,
+};
+builtin_platform_driver(aspeed_pciecfg_driver);
diff -Naur ori_linux/drivers/pci/controller/Kconfig linux/drivers/pci/controller/Kconfig
--- ori_linux/drivers/pci/controller/Kconfig	2022-09-06 15:47:39.134429509 +0800
+++ linux/drivers/pci/controller/Kconfig	2022-09-05 00:50:54.472374706 +0800
@@ -3,6 +3,12 @@
 menu "PCI controller drivers"
 	depends on PCI
 
+config PCIE_ASPEED
+	bool "ASPEED PCIe controller"
+	depends on ARCH_ASPEED
+	help
+	 Enables support for the PCIe controller in the ASPEED BMC SoC.
+
 config PCI_MVEBU
 	bool "Marvell EBU PCIe controller"
 	depends on ARCH_MVEBU || ARCH_DOVE || COMPILE_TEST
diff -Naur ori_linux/drivers/pci/controller/Makefile linux/drivers/pci/controller/Makefile
--- ori_linux/drivers/pci/controller/Makefile	2022-09-06 15:47:39.150425552 +0800
+++ linux/drivers/pci/controller/Makefile	2022-09-06 14:21:16.419840352 +0800
@@ -1,4 +1,5 @@
 # SPDX-License-Identifier: GPL-2.0
+obj-$(CONFIG_PCIE_ASPEED) += aspeed_pciecfg.o pcie-aspeed.o
 obj-$(CONFIG_PCIE_CADENCE) += pcie-cadence.o
 obj-$(CONFIG_PCIE_CADENCE_HOST) += pcie-cadence-host.o
 obj-$(CONFIG_PCIE_CADENCE_EP) += pcie-cadence-ep.o
diff -Naur ori_linux/drivers/pci/controller/pcie-aspeed.c linux/drivers/pci/controller/pcie-aspeed.c
--- ori_linux/drivers/pci/controller/pcie-aspeed.c	1970-01-01 08:00:00.000000000 +0800
+++ linux/drivers/pci/controller/pcie-aspeed.c	2022-09-06 14:18:36.475753730 +0800
@@ -0,0 +1,901 @@
+// SPDX-License-Identifier: GPL-2.0+
+/*
+ * PCIe host controller driver for ASPEED PCIe Bridge
+ *
+ */
+#include <linux/irqchip/chained_irq.h>
+#include <linux/irqdomain.h>
+#include <linux/iopoll.h>
+#include <linux/mfd/syscon.h>
+#include <linux/kernel.h>
+#include <linux/msi.h>
+#include <linux/module.h>
+#include <linux/platform_device.h>
+#include <linux/of_platform.h>
+#include <linux/of_address.h>
+#include <linux/of_irq.h>
+#include <linux/of_pci.h>
+#include <linux/pci.h>
+#include <linux/regmap.h>
+#include <linux/reset.h>
+
+#include "../pci.h"
+
+/*	PCI Host Controller registers */
+#define ASPEED_PCIE_CLASS_CODE		0x04
+#define ASPEED_PCIE_GLOBAL			0x30
+#define ASPEED_PCIE_CFG_DIN			0x50
+#define ASPEED_PCIE_CFG3			0x58
+#define ASPEED_PCIE_LOCK			0x7C
+#define ASPEED_PCIE_LINK			0xC0
+#define ASPEED_PCIE_INT				0xC4
+#define ASPEED_PCIE_LINK_STS		0xD0
+/*	AST_PCIE_CFG2			0x04 */
+#define PCIE_CFG_CLASS_CODE(x)	(x << 8)
+#define PCIE_CFG_REV_ID(x)		(x)
+/*	PEHR10: Miscellaneous Control 10H Register */
+#define DATALINK_REPORT_CAPABLE	BIT(4)
+/*	PEHR14: Miscellaneous Control 14H Register */
+#define HOTPLUG_CAPABLE_ENABLE	BIT(6)
+#define HOTPLUG_SURPRISE_ENABLE	BIT(5)
+#define ATTENTION_BUTTON_ENALBE	BIT(0)
+/*	PEHR30: Miscellaneous Control 30H Register */
+/* Disable RC synchronous reset when link up to link down*/
+#define RC_SYNC_RESET_DISABLE	BIT(20)
+#define ROOT_COMPLEX_ID(x)		(x << 4)
+#define PCIE_RC_SLOT_ENABLE		BIT(1)
+/*	AST_PCIE_LOCK			0x7C */
+#define PCIE_UNLOCK				0xa8
+/*	AST_PCIE_LINK			0xC0 */
+#define PCIE_LINK_STS			BIT(5)
+/*  ASPEED_PCIE_LINK_STS	0xD0 */
+#define PCIE_LINK_5G			BIT(17)
+#define PCIE_LINK_2_5G			BIT(16)
+
+/*	H2X Controller registers */
+/* reg 0x08 */
+#define PCIE_TX_IDLE_CLEAR		BIT(0)
+
+/* reg 0x24 */
+#define PCIE_TX_IDLE			BIT(31)
+
+#define PCIE_STATUS_OF_TX		GENMASK(25, 24)
+#define	PCIE_RC_TX_COMPLETE		0
+#define	PCIE_RC_L_TX_COMPLETE	BIT(24)
+#define	PCIE_RC_H_TX_COMPLETE	BIT(25)
+
+#define PCIE_TRIGGER_TX			BIT(0)
+
+/* reg 0x80, 0xC0 */
+#define PCIE_RX_TAG_MASK		GENMASK(23, 16)
+#define PCIE_RX_DMA_EN			BIT(9)
+#define PCIE_RX_LINEAR			BIT(8)
+#define PCIE_RX_MSI_SEL			BIT(7)
+#define PCIE_RX_MSI_EN			BIT(6)
+#define PCIE_1M_ADDRESS_EN		BIT(5)
+#define PCIE_UNLOCK_RX_BUFF		BIT(4)
+#define PCIE_RX_TLP_TAG_MATCH	BIT(3)
+#define PCIE_Wait_RX_TLP_CLR	BIT(2)
+#define PCIE_RC_RX_ENABLE		BIT(1)
+#define PCIE_RC_ENABLE			BIT(0)
+
+/* reg 0x88, 0xC8 : RC ISR */
+#define PCIE_RC_CPLCA_ISR		BIT(6)
+#define PCIE_RC_CPLUR_ISR		BIT(5)
+#define PCIE_RC_RX_DONE_ISR		BIT(4)
+
+#define PCIE_RC_INTD_ISR		BIT(3)
+#define PCIE_RC_INTC_ISR		BIT(2)
+#define PCIE_RC_INTB_ISR		BIT(1)
+#define PCIE_RC_INTA_ISR		BIT(0)
+
+#define MAX_MSI_HOST_IRQS		64
+
+struct aspeed_pcie {
+	struct device *dev;
+	void __iomem *reg;	//rc slot base
+	int domain;
+	char name[10];
+	u32 msi_address;
+	int	irq;
+	u8 txTag;
+	struct resource mem;
+	unsigned int busnr;
+	struct regmap *cfg;	//pciecfg
+	struct regmap *pciephy; //pcie_phy
+	struct reset_control *phy_rst;
+	/* INTx */
+	struct irq_domain *irq_domain;	//irq_domain
+	// msi
+	struct irq_domain *dev_domain;	//inner_domain
+	struct irq_domain *msi_domain;
+	struct mutex lock;
+	int hotplug_event;
+	DECLARE_BITMAP(msi_irq_in_use, MAX_MSI_HOST_IRQS);
+};
+
+static void aspeed_pcie_intx_ack_irq(struct irq_data *d)
+{
+	struct aspeed_pcie *pcie = irq_data_get_irq_chip_data(d);
+
+	writel(readl(pcie->reg + 0x04) | BIT(d->hwirq), pcie->reg + 0x04);
+}
+
+static void aspeed_pcie_intx_mask_irq(struct irq_data *d)
+{
+	struct aspeed_pcie *pcie = irq_data_get_irq_chip_data(d);
+
+	writel(readl(pcie->reg + 0x04) & ~BIT(d->hwirq), pcie->reg + 0x04);
+}
+
+static void aspeed_pcie_intx_unmask_irq(struct irq_data *d)
+{
+	struct aspeed_pcie *pcie = irq_data_get_irq_chip_data(d);
+
+	writel(readl(pcie->reg + 0x04) | BIT(d->hwirq), pcie->reg + 0x04);
+}
+
+static struct irq_chip aspeed_intx_irq_chip = {
+	.name = "ASPEED:IntX",
+	.irq_ack = aspeed_pcie_intx_ack_irq,
+	.irq_mask = aspeed_pcie_intx_mask_irq,
+	.irq_unmask = aspeed_pcie_intx_unmask_irq,
+};
+
+static int aspeed_pcie_intx_map(struct irq_domain *domain, unsigned int irq,
+			  irq_hw_number_t hwirq)
+{
+	irq_set_chip_and_handler(irq, &aspeed_intx_irq_chip, handle_level_irq);
+	irq_set_chip_data(irq, domain->host_data);
+	irq_set_status_flags(irq, IRQ_LEVEL);
+
+	return 0;
+}
+
+/* INTx IRQ Domain operations */
+static const struct irq_domain_ops aspeed_intx_domain_ops = {
+	.map = aspeed_pcie_intx_map,
+};
+
+static void aspeed_pcie_intr_handler(struct irq_desc *desc)
+{
+	struct aspeed_pcie *pcie = irq_desc_get_handler_data(desc);
+	struct irq_chip *irqchip = irq_desc_get_chip(desc);
+	unsigned long status;
+	unsigned long intx;
+	u32 virq;
+	u32 bit;
+	int i;
+
+	chained_irq_enter(irqchip, desc);
+
+	intx = readl(pcie->reg + 0x08) & 0xf;
+
+	if (intx) {
+		for_each_set_bit(bit, &intx, PCI_NUM_INTX) {
+			virq = irq_find_mapping(pcie->irq_domain, bit);
+			if (virq)
+				generic_handle_irq(virq);
+			else
+				dev_err(pcie->dev, "unexpected Int - X\n");
+		}
+	}
+
+	if (IS_ENABLED(CONFIG_PCI_MSI)) {
+		for (i = 0; i < 2; i++) {
+			status = readl(pcie->reg + 0x28 + (i * 4));
+			writel(status, pcie->reg + 0x28 + (i * 4));
+			if (!status)
+				continue;
+
+			for_each_set_bit(bit, &status, 32) {
+				if (i)
+					bit += 32;
+				virq = irq_find_mapping(pcie->msi_domain, bit);
+				if (virq)
+					generic_handle_irq(virq);
+				else
+					dev_err(pcie->dev, "unexpected MSI\n");
+			}
+		}
+	}
+	chained_irq_exit(irqchip, desc);
+
+}
+
+//optional : set_slot_power_limit
+void aspeed_pcie_set_slot_power_limit(struct aspeed_pcie *pcie)
+{
+	u32 cfg_val, isr;
+	int ret;
+
+	writel(BIT(4) | readl(pcie->reg), pcie->reg);
+
+	pcie->txTag %= 0x7;
+	regmap_write(pcie->cfg, 0x10, 0x74000001);
+	switch (pcie->domain) {
+	case 0: //write for 0.8.0
+		regmap_write(pcie->cfg, 0x14, 0x00400050 | (pcie->txTag << 8));
+	break;
+	case 1: //write for 0.4.0
+		regmap_write(pcie->cfg, 0x14, 0x00200050 | (pcie->txTag << 8));
+	break;
+	}
+
+	regmap_write(pcie->cfg, 0x18, 0);
+	regmap_write(pcie->cfg, 0x1C, 0);
+	regmap_write(pcie->cfg, 0x20, 0x1a);
+
+	//trigger tx
+	regmap_write_bits(pcie->cfg, 0x24, PCIE_TRIGGER_TX, PCIE_TRIGGER_TX);
+
+	//wait tx idle
+	ret = regmap_read_poll_timeout(
+							pcie->cfg, 0x24, cfg_val,
+							(cfg_val & PCIE_TX_IDLE),
+							0, 10);
+	if (ret)
+		goto out;
+
+	//write clr tx idle
+	regmap_write_bits(pcie->cfg, 0x08, PCIE_TX_IDLE_CLEAR, PCIE_TX_IDLE_CLEAR);
+
+	//check tx status
+	regmap_read(pcie->cfg, 0x24, &cfg_val);
+	switch (cfg_val & PCIE_STATUS_OF_TX) {
+	case PCIE_RC_L_TX_COMPLETE:
+	case PCIE_RC_H_TX_COMPLETE:
+		ret = readl_poll_timeout(
+					pcie->reg + 0x08, isr,
+					(isr & PCIE_RC_RX_DONE_ISR),
+					0, 10);
+		if (ret)
+			dev_err(pcie->dev, "[%d] : tx timeout [%x]\n", pcie->domain, isr);
+
+		writel(readl(pcie->reg + 0x08), pcie->reg + 0x08);
+	break;
+	}
+out:
+	pcie->txTag++;
+}
+
+static int aspeed_h2x_rd_conf(struct pci_bus *bus, unsigned int devfn,
+				int where, int size, u32 *val)
+{
+	struct aspeed_pcie *pcie = bus->sysdata;
+	u32 bdf_offset;
+	int rx_done_fail = 0;
+	u32 cfg_val, isr, type = 0;
+	u32 link_sts = 0;
+	int ret;
+
+	//H2X80[4] (unlock) is write-only.
+	//Driver may set H2X80[4]=1 before triggering next TX config.
+	writel(BIT(4) | readl(pcie->reg), pcie->reg);
+
+	switch (pcie->domain) {
+	case 0:
+		if (!bus->number) {
+			switch (PCI_SLOT(devfn)) {
+			case 0:
+			case 4:
+				break;
+			default:
+				*val = 0xffffffff;
+				return PCIBIOS_SUCCESSFUL;
+			}
+		}
+
+		if (bus->number)
+			type = 1;
+		else
+			type = 0;
+		break;
+	case 1:
+		if (bus->number == 128) {
+			switch (PCI_SLOT(devfn)) {
+			case 0:
+			case 8:
+				break;
+			default:
+				*val = 0xffffffff;
+				return PCIBIOS_SUCCESSFUL;
+			}
+		}
+
+		if (bus->number > 128)
+			type = 1;
+		else
+			type = 0;
+		break;
+	}
+
+//	printk("[%d]R:b d f [%d:%d:%d] devfn %x\n", pcie->domain, bus->number, PCI_SLOT(devfn), PCI_FUNC(devfn), devfn);
+
+	if (type) {
+		regmap_read(pcie->pciephy, ASPEED_PCIE_LINK, &link_sts);
+		if (!(link_sts & PCIE_LINK_STS)) {
+			*val = 0xffffffff;
+			return PCIBIOS_SUCCESSFUL;
+		}
+	}
+
+	bdf_offset = ((bus->number) << 24) |
+					(PCI_SLOT(devfn) << 19) |
+					(PCI_FUNC(devfn) << 16) |
+					(where & ~3);
+
+	pcie->txTag %= 0x7;
+
+	regmap_write(pcie->cfg, 0x10, 0x04000001 | (type << 24));
+	regmap_write(pcie->cfg, 0x14, 0x0000200f | (pcie->txTag << 8));
+	regmap_write(pcie->cfg, 0x18, bdf_offset);
+	regmap_write(pcie->cfg, 0x1C, 0x00000000);
+
+	//trigger tx
+	regmap_write_bits(pcie->cfg, 0x24, PCIE_TRIGGER_TX, PCIE_TRIGGER_TX);
+
+	//wait tx idle
+	//todo find timeout and time period
+	ret = regmap_read_poll_timeout(pcie->cfg, 0x24, cfg_val, (cfg_val & PCIE_TX_IDLE),
+									0, 10);
+	if (ret) {
+		dev_err(pcie->dev, "[%d] : tx idle timeout [%x]\n", pcie->domain, cfg_val);
+		*val = 0xffffffff;
+		goto out;
+	}
+
+	//write clr tx idle
+	regmap_write_bits(pcie->cfg, 0x08, PCIE_TX_IDLE_CLEAR, PCIE_TX_IDLE_CLEAR);
+
+	//check tx status
+	regmap_read(pcie->cfg, 0x24, &cfg_val);
+
+	switch (cfg_val & PCIE_STATUS_OF_TX) {
+	case PCIE_RC_L_TX_COMPLETE:		//domain 0
+		if (pcie->domain != 0)
+			dev_err(pcie->dev, "[%d] : tx complete no correct\n", pcie->domain);
+		fallthrough;
+	case PCIE_RC_H_TX_COMPLETE:		//domain 1
+		ret = readl_poll_timeout(pcie->reg + 0x08, isr, (isr & PCIE_RC_RX_DONE_ISR),
+					 0,
+					 10);
+		if (ret) {
+			dev_err(pcie->dev, "[%d] : rx done timeout\n", pcie->domain);
+			rx_done_fail = 1;
+			*val = 0xffffffff;
+		}
+		if (!rx_done_fail) {
+			if (readl(pcie->reg + 0x14) & BIT(13))
+				*val = 0xffffffff;
+			else
+				*val = readl(pcie->reg + 0x0C);
+		}
+
+		writel(BIT(4) | readl(pcie->reg), pcie->reg);
+		writel(readl(pcie->reg + 0x08), pcie->reg + 0x08);
+		break;
+	case PCIE_STATUS_OF_TX:
+		*val = 0xffffffff;
+		break;
+	default:	//read rc data
+		regmap_read(pcie->cfg, 0x0C, &cfg_val);
+		*val = cfg_val;
+		break;
+	}
+
+	switch (size) {
+	case 1:
+		*val = (*val >> ((where & 3) * 8)) & 0xff;
+		break;
+	case 2:
+		*val = (*val >> ((where & 2) * 8)) & 0xffff;
+		break;
+	}
+//	printk("R:b d f [%d:%d:%d] where:%x : %x\n", bus->number, PCI_SLOT(devfn), PCI_FUNC(devfn), where, *val);
+
+#ifdef CONFIG_HOTPLUG_PCI
+	switch (pcie->domain) {
+	case 0:
+		if ((where == 0x9a) && (bus->number == 0x0) &&
+			(PCI_SLOT(devfn) == 0x4) && (PCI_FUNC(devfn) == 0x0) &&
+			pcie->hotplug_event)
+			*val |= PCI_EXP_SLTSTA_ABP;
+		break;
+	case 1:
+		if ((where == 0x9a) && (bus->number == 128) &&
+			(PCI_SLOT(devfn) == 0x8) && (PCI_FUNC(devfn) == 0x0) &&
+			pcie->hotplug_event)
+			*val |= PCI_EXP_SLTSTA_ABP;
+		break;
+	}
+#endif
+out:
+	pcie->txTag++;
+	return PCIBIOS_SUCCESSFUL;
+
+}
+
+static int
+aspeed_h2x_wr_conf(struct pci_bus *bus, unsigned int devfn,
+				int where, int size, u32 val)
+{
+	u32 type = 0;
+	u32 shift = 8 * (where & 3);
+	u32 bdf_offset;
+	u8 byte_en = 0;
+	struct aspeed_pcie *pcie = bus->sysdata;
+	u32 isr, cfg_val;
+	int ret;
+
+#ifdef CONFIG_HOTPLUG_PCI
+	switch (pcie->domain) {
+	case 0:
+		if ((where == 0x9a) && (bus->number == 0x0) &&
+			(PCI_SLOT(devfn) == 0x4) && (PCI_FUNC(devfn) == 0x0) &&
+			pcie->hotplug_event && (val & PCI_EXP_SLTSTA_ABP)) {
+			pcie->hotplug_event = 0;
+			return PCIBIOS_SUCCESSFUL;
+		}
+		break;
+	case 1:
+		if ((where == 0x9a) && (bus->number == 128) &&
+			(PCI_SLOT(devfn) == 0x8) && (PCI_FUNC(devfn) == 0x0) &&
+			pcie->hotplug_event && (val & PCI_EXP_SLTSTA_ABP)) {
+			pcie->hotplug_event = 0;
+			return PCIBIOS_SUCCESSFUL;
+		}
+		break;
+	}
+#endif
+
+
+	//printk("W b d f [%d:%d:%d] : where %x : val %x\n", bus->number, PCI_SLOT(devfn), PCI_FUNC(devfn), where, val);
+
+	//H2X80[4] (unlock) is write-only.
+	//Driver may set H2X80[4]=1 before triggering next TX config.
+	writel(BIT(4) | readl(pcie->reg), pcie->reg);
+
+	switch (size) {
+	case 1:
+		switch (where % 4) {
+		case 0:
+			byte_en = 0x1;
+			break;
+		case 1:
+			byte_en = 0x2;
+			break;
+		case 2:
+			byte_en = 0x4;
+			break;
+		case 3:
+			byte_en = 0x8;
+			break;
+		}
+		val = (val & 0xff) << shift;
+		break;
+	case 2:
+		switch ((where >> 1) % 2) {
+		case 0:
+			byte_en = 0x3;
+			break;
+		case 1:
+			byte_en = 0xc;
+			break;
+		}
+		val = (val & 0xffff) << shift;
+		break;
+	default:
+		byte_en = 0xf;
+		break;
+	}
+
+	switch (pcie->domain) {
+	case 0:
+		if (bus->number)
+			type = 1;
+		else
+			type = 0;
+		break;
+	case 1:
+		if (bus->number > 128)
+			type = 1;
+		else
+			type = 0;
+		break;
+	}
+
+	bdf_offset = (bus->number << 24) | (PCI_SLOT(devfn) << 19) |
+					(PCI_FUNC(devfn) << 16) | (where & ~3);
+	pcie->txTag %= 0x7;
+
+	regmap_write(pcie->cfg, 0x10, 0x44000001 | (type << 24));
+	regmap_write(pcie->cfg, 0x14, 0x00002000 | (pcie->txTag << 8) | byte_en);
+	regmap_write(pcie->cfg, 0x18, bdf_offset);
+	regmap_write(pcie->cfg, 0x1C, 0x00000000);
+	regmap_write(pcie->cfg, 0x20, val);
+
+	//trigger tx
+	regmap_write_bits(pcie->cfg, 0x24, PCIE_TRIGGER_TX, PCIE_TRIGGER_TX);
+
+	//wait tx idle
+	//todo find timeout and time period
+	ret = regmap_read_poll_timeout(pcie->cfg, 0x24, cfg_val, (cfg_val & PCIE_TX_IDLE),
+									0, 10);
+	if (ret) {
+		dev_err(pcie->dev, "[%d] : tx idle timeout [%x]\n", pcie->domain, cfg_val);
+		goto out;
+	}
+
+	//write clr tx idle
+	regmap_write_bits(pcie->cfg, 0x08, PCIE_TX_IDLE_CLEAR, PCIE_TX_IDLE_CLEAR);
+
+	//check tx status
+	regmap_read(pcie->cfg, 0x24, &cfg_val);
+
+	switch (cfg_val & PCIE_STATUS_OF_TX) {
+	case PCIE_RC_L_TX_COMPLETE:
+	case PCIE_RC_H_TX_COMPLETE:
+		ret = readl_poll_timeout(
+							pcie->reg + 0x08, isr,
+							(isr & PCIE_RC_RX_DONE_ISR),
+							0, 10);
+		if (ret)
+			dev_err(pcie->dev, "[%d] : tx timeout\n", pcie->domain);
+
+		writel(readl(pcie->reg + 0x08), pcie->reg + 0x08);
+		break;
+	}
+
+out:
+	pcie->txTag++;
+	return PCIBIOS_SUCCESSFUL;
+
+}
+
+/* PCIe operations */
+static struct pci_ops aspeed_pcie_ops = {
+	.read	= aspeed_h2x_rd_conf,
+	.write	= aspeed_h2x_wr_conf,
+};
+
+#ifdef CONFIG_PCI_MSI
+static void aspeed_msi_compose_msi_msg(struct irq_data *data, struct msi_msg *msg)
+{
+	struct aspeed_pcie *pcie = irq_data_get_irq_chip_data(data);
+
+	msg->address_hi = 0;
+	msg->address_lo = pcie->msi_address;
+	msg->data = data->hwirq;
+}
+
+static int aspeed_msi_set_affinity(struct irq_data *irq_data,
+				 const struct cpumask *mask, bool force)
+{
+	return -EINVAL;
+}
+
+static struct irq_chip aspeed_msi_bottom_irq_chip = {
+	.name = "ASPEED MSI",
+	.irq_compose_msi_msg = aspeed_msi_compose_msi_msg,
+	.irq_set_affinity = aspeed_msi_set_affinity,
+};
+
+static int aspeed_irq_msi_domain_alloc(struct irq_domain *domain, unsigned int virq,
+					unsigned int nr_irqs, void *args)
+{
+	struct aspeed_pcie *pcie = domain->host_data;
+	int bit;
+	int i;
+
+	mutex_lock(&pcie->lock);
+
+	bit = bitmap_find_free_region(pcie->msi_irq_in_use, MAX_MSI_HOST_IRQS,
+				      get_count_order(nr_irqs));
+	if (bit < 0)
+		return -ENOSPC;
+
+	for (i = 0; i < nr_irqs; i++) {
+		irq_domain_set_info(domain, virq + i, bit + i, &aspeed_msi_bottom_irq_chip,
+				domain->host_data, handle_simple_irq,
+				NULL, NULL);
+	}
+
+	mutex_unlock(&pcie->lock);
+
+	return 0;
+}
+
+static void aspeed_irq_msi_domain_free(struct irq_domain *domain, unsigned int virq,
+					unsigned int nr_irqs)
+{
+	struct irq_data *data = irq_domain_get_irq_data(domain, virq);
+	struct aspeed_pcie *pcie = irq_data_get_irq_chip_data(data);
+
+	mutex_lock(&pcie->lock);
+
+	bitmap_release_region(pcie->msi_irq_in_use, data->hwirq,
+			      get_count_order(nr_irqs));
+
+	mutex_unlock(&pcie->lock);
+
+}
+
+static void aspeed_pcie_msi_enable(struct aspeed_pcie *pcie)
+{
+	writel(0xffffffff, pcie->reg + 0x20);
+	writel(0xffffffff, pcie->reg + 0x24);
+}
+
+static const struct irq_domain_ops aspeed_msi_domain_ops = {
+	.alloc  = aspeed_irq_msi_domain_alloc,
+	.free   = aspeed_irq_msi_domain_free,
+};
+
+static struct irq_chip aspeed_msi_irq_chip = {
+	.name = "PCIe MSI",
+	.irq_enable = pci_msi_unmask_irq,
+	.irq_disable = pci_msi_mask_irq,
+	.irq_mask = pci_msi_mask_irq,
+	.irq_unmask = pci_msi_unmask_irq,
+};
+
+static struct msi_domain_info aspeed_msi_domain_info = {
+	.flags = (MSI_FLAG_USE_DEF_DOM_OPS | MSI_FLAG_USE_DEF_CHIP_OPS |
+				MSI_FLAG_MULTI_PCI_MSI),
+	.chip = &aspeed_msi_irq_chip,
+};
+#endif
+
+static int aspeed_pcie_init_irq_domain(struct aspeed_pcie *pcie)
+{
+	struct device *dev = pcie->dev;
+	struct device_node *node = dev->of_node;
+	struct device_node *pcie_intc_node;
+#ifdef CONFIG_PCI_MSI
+	struct fwnode_handle *fwnode = dev_fwnode(pcie->dev);
+	struct irq_domain *parent;
+#endif
+
+	/* Setup INTx */
+	pcie_intc_node = of_get_next_child(node, NULL);
+	if (!pcie_intc_node) {
+		dev_err(dev, "No PCIe Intc node found\n");
+		return -ENODEV;
+	}
+
+	pcie->irq_domain = irq_domain_add_linear(pcie_intc_node, PCI_NUM_INTX, &aspeed_intx_domain_ops, pcie);
+
+	if (!pcie->irq_domain) {
+		dev_err(dev, "failed to get an INTx IRQ domain\n");
+		return -ENOMEM;
+	}
+
+	of_node_put(pcie_intc_node);
+
+	//080 can't config for msi
+	if (pcie->domain)
+		return 0;
+
+#ifdef CONFIG_PCI_MSI
+	pcie->dev_domain = irq_domain_add_linear(NULL, MAX_MSI_HOST_IRQS, &aspeed_msi_domain_ops, pcie);
+	if (!pcie->dev_domain) {
+		dev_err(pcie->dev, "failed to create IRQ domain\n");
+		return -ENOMEM;
+	}
+
+	pcie->msi_domain = pci_msi_create_irq_domain(fwnode, &aspeed_msi_domain_info, pcie->dev_domain);
+	if (!pcie->msi_domain) {
+		dev_err(pcie->dev, "failed to create MSI domain\n");
+		irq_domain_remove(parent);
+		return -ENOMEM;
+	}
+	aspeed_pcie_msi_enable(pcie);
+#endif
+
+	return 0;
+}
+
+static void aspeed_pcie_port_init(struct aspeed_pcie *pcie)
+{
+	u32 link_sts = 0;
+
+	//plda init
+	regmap_write(pcie->pciephy, ASPEED_PCIE_LOCK, PCIE_UNLOCK);
+//	regmap_write(pcie->pciephy, ASPEED_PCIE_CLASS_CODE, PCIE_CFG_CLASS_CODE(0x60000) | PCIE_CFG_REV_ID(4));
+#ifdef CONFIG_HOTPLUG_PCI
+	regmap_write(pcie->pciephy, ASPEED_PCIE_GLOBAL, RC_SYNC_RESET_DISABLE | ROOT_COMPLEX_ID(0x3) | PCIE_RC_SLOT_ENABLE);
+	regmap_write(pcie->pciephy, 0x10, 0xd7040022 | DATALINK_REPORT_CAPABLE);
+	regmap_write(pcie->pciephy, 0x14, HOTPLUG_CAPABLE_ENABLE | HOTPLUG_SURPRISE_ENABLE | ATTENTION_BUTTON_ENALBE);
+#else
+	regmap_write(pcie->pciephy, ASPEED_PCIE_GLOBAL, ROOT_COMPLEX_ID(0x3));
+#endif
+
+	reset_control_deassert(pcie->phy_rst);
+	mdelay(500);
+
+	//clr intx isr
+	writel(0x0, pcie->reg + 0x04);
+
+	//clr msi isr
+	writel(0xFFFFFFFF, pcie->reg + 0x28);
+	writel(0xFFFFFFFF, pcie->reg + 0x2c);
+
+	//rc_l
+//	0x80: 040 set bit7 0
+//	0xC0: 080 set bit7 1
+	if (pcie->domain)
+		writel(PCIE_RX_DMA_EN | PCIE_RX_LINEAR | PCIE_RX_MSI_SEL | PCIE_RX_MSI_EN |
+				PCIE_Wait_RX_TLP_CLR | PCIE_RC_RX_ENABLE | PCIE_RC_ENABLE, pcie->reg);
+	else
+		writel(PCIE_RX_DMA_EN | PCIE_RX_LINEAR | PCIE_RX_MSI_EN |
+				PCIE_Wait_RX_TLP_CLR | PCIE_RC_RX_ENABLE | PCIE_RC_ENABLE, pcie->reg);
+
+	//assign debug tx tag
+	writel(0x28, pcie->reg + 0x3C);
+
+	regmap_read(pcie->pciephy, ASPEED_PCIE_LINK, &link_sts);
+	if (link_sts & PCIE_LINK_STS) {
+//		aspeed_pcie_set_slot_power_limit(pcie);
+		dev_info(pcie->dev, "PCIE- Link up\n");
+//		if (readl(pcie->pciereg_base
+//				+ ASPEED_PCIE_LINK_STS) & PCIE_LINK_2_5G)
+//			dev_info(pcie->dev, "PCIE- Link up : 2.5G\n");
+	} else {
+		dev_info(pcie->dev, "PCIE- Link down\n");
+	}
+}
+
+static int aspeed_pcie_setup(struct aspeed_pcie *pcie)
+{
+	struct device *dev = pcie->dev;
+	struct platform_device *pdev = to_platform_device(dev);
+	struct pci_host_bridge *host = pci_host_bridge_from_priv(pcie);
+	struct list_head *windows = &host->windows;
+	struct resource_entry *win, *tmp_win;
+	resource_size_t io_base;
+	struct device_node *node = dev->of_node;
+	struct device_node *cfg_node;
+	int err;
+
+	err = devm_of_pci_get_host_bridge_resources(dev, 0, 0xff,
+						    windows, &io_base);
+	if (err)
+		return err;
+
+	err = devm_request_pci_bus_resources(dev, windows);
+	if (err < 0)
+		return err;
+
+	/* Get the I/O and memory ranges from DT */
+	resource_list_for_each_entry_safe(win, tmp_win, windows) {
+		switch (resource_type(win->res)) {
+		case IORESOURCE_IO:
+			err = devm_pci_remap_iospace(dev, win->res, io_base);
+			if (err) {
+				dev_warn(dev, "error %d: failed to map resource %pR\n",
+					 err, win->res);
+				resource_list_destroy_entry(win);
+			}
+			break;
+		case IORESOURCE_MEM:
+			memcpy(&pcie->mem, win->res, sizeof(*win->res));
+			pcie->mem.name = "non-prefetchable";
+			break;
+		case IORESOURCE_BUS:
+			pcie->busnr = win->res->start;
+			break;
+		}
+	}
+
+	pcie->reg = devm_platform_ioremap_resource(pdev, 0);
+
+	cfg_node = of_find_compatible_node(NULL, NULL,
+					   "aspeed,ast2600-pciecfg");
+	if (cfg_node) {
+		pcie->cfg = syscon_node_to_regmap(cfg_node);
+		if (IS_ERR(pcie->cfg))
+			return PTR_ERR(pcie->cfg);
+	}
+
+	pcie->pciephy = syscon_regmap_lookup_by_phandle(node, "pciephy");
+	if (IS_ERR(pcie->pciephy)) {
+		dev_err(dev, "failed to map pciephy base\n");
+		return PTR_ERR(pcie->pciephy);
+	}
+
+	of_property_read_u32(node, "msi_address", &pcie->msi_address);
+	of_property_read_u32(node, "linux,pci-domain", &pcie->domain);
+
+	pcie->irq = irq_of_parse_and_map(node, 0);
+	if (pcie->irq < 0)
+		return pcie->irq;
+
+	pcie->phy_rst = devm_reset_control_get_shared(pcie->dev, NULL);
+	if (IS_ERR(pcie->phy_rst)) {
+		dev_err(&pdev->dev, "can't get pcie phy reset\n");
+		return PTR_ERR(pcie->phy_rst);
+	}
+
+	aspeed_pcie_port_init(pcie);
+
+	err = aspeed_pcie_init_irq_domain(pcie);
+	if (err) {
+		dev_err(dev, "failed to init PCIe IRQ domain\n");
+		return err;
+	}
+
+	irq_set_chained_handler_and_data(pcie->irq,
+					 aspeed_pcie_intr_handler, pcie);
+
+	return 0;
+
+}
+
+static ssize_t hotplug_store(struct device *dev,
+		struct device_attribute *attr, const char *buf, size_t len)
+{
+	struct aspeed_pcie *pcie = dev_get_drvdata(dev);
+
+	pcie->hotplug_event = 1;
+
+	return len;
+}
+
+static DEVICE_ATTR_WO(hotplug);
+
+static int aspeed_pcie_probe(struct platform_device *pdev)
+{
+	struct device *dev = &pdev->dev;
+	struct pci_host_bridge *host;
+	struct aspeed_pcie *pcie;
+	int err;
+
+	host = devm_pci_alloc_host_bridge(dev, sizeof(*pcie));
+	if (!host)
+		return -ENODEV;
+
+	pcie = pci_host_bridge_priv(host);
+	pcie->dev = dev;
+	pcie->txTag = 0;
+	platform_set_drvdata(pdev, pcie);
+
+	err = aspeed_pcie_setup(pcie);
+	if (err) {
+		dev_err(dev, "Parsing DT failed\n");
+		return err;
+	}
+
+	host->busnr = pcie->busnr;
+	host->dev.parent = pcie->dev;
+	host->ops = &aspeed_pcie_ops;
+	host->map_irq = of_irq_parse_and_map_pci;
+	host->swizzle_irq = pci_common_swizzle;
+	host->sysdata = pcie;
+
+	err = sysfs_create_file(&pdev->dev.kobj, &dev_attr_hotplug.attr);
+	if (err) {
+		dev_err(&pdev->dev, "unable to create sysfs interface\n");
+		return err;
+	}
+
+
+	return pci_host_probe(host);
+}
+
+static const struct of_device_id aspeed_pcie_of_match[] = {
+	{ .compatible = "aspeed,ast2600-pcie", },
+	{}
+};
+
+static struct platform_driver aspeed_pcie_driver = {
+	.driver = {
+		.name = "aspeed-pcie",
+		.suppress_bind_attrs = true,
+		.of_match_table = aspeed_pcie_of_match,
+	},
+	.probe = aspeed_pcie_probe,
+};
+
+module_platform_driver(aspeed_pcie_driver);
+MODULE_LICENSE("GPL v2");
diff -Naur ori_linux/drivers/pci/probe.c linux/drivers/pci/probe.c
--- ori_linux/drivers/pci/probe.c	2022-09-06 15:47:39.194414666 +0800
+++ linux/drivers/pci/probe.c	2022-09-06 16:02:59.641130478 +0800
@@ -365,6 +365,14 @@
 	if (bridge->vendor == PCI_VENDOR_ID_DEC && bridge->device == 0x0001)
 		return;
 
+	if ((bridge->vendor == 0x1a03 && bridge->device == 0x1150)) {
+		u16 reg16;
+		dev_info(&bridge->dev, "ASPEED Bridge Gen2 re-training\n");
+		pcie_capability_read_word(bridge, PCI_EXP_LNKCTL, &reg16);
+		reg16 |= PCI_EXP_LNKCTL_RL;
+		pcie_capability_write_word(bridge, PCI_EXP_LNKCTL, reg16);
+	}
+
 	pci_read_config_dword(bridge, PCI_PREF_MEMORY_BASE, &pmem);
 	if (!pmem) {
 		pci_write_config_dword(bridge, PCI_PREF_MEMORY_BASE,
