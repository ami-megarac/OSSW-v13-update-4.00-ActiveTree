--- linux-5.4.85/include/linux/dma-mapping.h	2021-04-15 16:08:56.561485194 +0800
+++ linux-5.4.85-new/include/linux/dma-mapping.h	2021-04-19 17:10:43.589355497 +0800
@@ -263,9 +263,9 @@
 
 static inline const struct dma_map_ops *get_dma_ops(struct device *dev)
 {
-	if (dev->dma_ops)
+	if (dev && dev->dma_ops)
 		return dev->dma_ops;
-	return get_arch_dma_ops(dev->bus);
+	return get_arch_dma_ops(dev ? dev->bus : NULL);
 }
 
 static inline void set_dma_ops(struct device *dev,
@@ -658,7 +658,7 @@
 
 static inline u64 dma_get_mask(struct device *dev)
 {
-	if (dev->dma_mask && *dev->dma_mask)
+	if (dev && dev->dma_mask && *dev->dma_mask)
 		return *dev->dma_mask;
 	return DMA_BIT_MASK(32);
 }
--- linux-5.4.85/kernel/dma/direct.c	2021-04-15 16:09:02.893357803 +0800
+++ linux-5.4.85-new/kernel/dma/direct.c	2021-04-19 17:11:16.436472953 +0800
@@ -327,7 +327,7 @@
 		size_t size)
 {
 	return swiotlb_force != SWIOTLB_FORCE &&
-		dma_capable(dev, dma_addr, size);
+		(!dev || dma_capable(dev, dma_addr, size));
 }
 
 dma_addr_t dma_direct_map_page(struct device *dev, struct page *page,
--- linux-5.4.85/kernel/dma/mapping.c	2021-04-15 16:09:02.893357803 +0800
+++ linux-5.4.85-new/kernel/dma/mapping.c	2021-04-19 17:11:31.408073090 +0800
@@ -300,7 +300,7 @@
 	const struct dma_map_ops *ops = get_dma_ops(dev);
 	void *cpu_addr;
 
-	WARN_ON_ONCE(!dev->coherent_dma_mask);
+	WARN_ON_ONCE(dev && !dev->coherent_dma_mask);
 
 	if (dma_alloc_from_dev_coherent(dev, size, dma_handle, &cpu_addr))
 		return cpu_addr;
