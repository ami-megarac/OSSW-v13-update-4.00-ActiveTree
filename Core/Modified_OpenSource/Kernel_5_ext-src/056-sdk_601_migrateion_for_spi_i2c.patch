diff -Naur linux_org/drivers/i2c/busses/i2c-new-aspeed.c linux/drivers/i2c/busses/i2c-new-aspeed.c
--- linux_org/drivers/i2c/busses/i2c-new-aspeed.c	2021-05-11 16:20:45.622912096 +0800
+++ linux/drivers/i2c/busses/i2c-new-aspeed.c	2021-05-10 10:03:23.000000000 +0800
@@ -504,12 +504,13 @@
 	u32 ctrl, state;
 	int r;
 	int ret = 0;
-
+    short slv_en = 0;
 	dev_dbg(i2c_bus->dev, "%d-bus aspeed_new_i2c_recover_bus [%x] \n", i2c_bus->adap.nr,
 		aspeed_i2c_read(i2c_bus, AST_I2CC_STS_AND_BUFF));
 
 	ctrl = aspeed_i2c_read(i2c_bus, AST_I2CC_FUN_CTRL);
-
+	if(ctrl & AST_I2CC_SLAVE_EN)
+		slv_en = 1;
 	aspeed_i2c_write(i2c_bus, ctrl & ~(AST_I2CC_MASTER_EN | AST_I2CC_SLAVE_EN),
 				AST_I2CC_FUN_CTRL);
 
@@ -540,6 +541,9 @@
 		dev_dbg(i2c_bus->dev, "can't recovery this situation\n");
 		ret = -EPROTO;
 	}
+	if(slv_en)
+		aspeed_i2c_write(i2c_bus, aspeed_i2c_read(i2c_bus, AST_I2CC_FUN_CTRL) | AST_I2CC_SLAVE_EN,
+				AST_I2CC_FUN_CTRL);
 	dev_dbg(i2c_bus->dev, "Recovery done [%x]\n", aspeed_i2c_read(i2c_bus, AST_I2CC_STS_AND_BUFF));
 
 	return ret;
@@ -695,7 +699,7 @@
 				if (i2c_bus->mode == DMA_MODE) {
 					cmd |= AST_I2CS_TX_DMA_EN;
 					i2c_slave_event(i2c_bus->slave, I2C_SLAVE_READ_REQUESTED, &i2c_bus->slave_dma_buf[0]);
-#ifdef CONFIG_I2C_SLAVE_EEPROM	//one byte send back
+#if 1 				//currently i2c slave framework only support one byte request. 
 					dev_dbg(i2c_bus->dev, "tx: [%x]\n", i2c_bus->slave_dma_buf[0]);
 					aspeed_i2c_write(i2c_bus, AST_I2CS_SET_TX_DMA_LEN(1), AST_I2CS_DMA_LEN);
 #else
@@ -708,7 +712,7 @@
 				} else if (i2c_bus->mode == BUFF_MODE) {
 					cmd |= AST_I2CS_TX_BUFF_EN;
 					i2c_slave_event(i2c_bus->slave, I2C_SLAVE_READ_REQUESTED, &byte_data);
-#ifdef CONFIG_I2C_SLAVE_EEPROM
+#if 1				//currently i2c slave framework only support one byte request. 
 					dev_dbg(i2c_bus->dev, "tx : [%02x]", byte_data);
 					writeb(byte_data, i2c_bus->buf_base);
 					aspeed_i2c_write(i2c_bus, AST_I2CC_SET_TX_BUF_LEN(1), AST_I2CC_BUFF_CTRL);
diff -Naur linux_org/drivers/mtd/spi-nor/spi-nor.c linux/drivers/mtd/spi-nor/spi-nor.c
--- linux_org/drivers/mtd/spi-nor/spi-nor.c	2021-05-11 16:20:37.523127825 +0800
+++ linux/drivers/mtd/spi-nor/spi-nor.c	2021-05-10 18:02:47.000000000 +0800
@@ -241,55 +241,45 @@
 #define JEDEC_MFR(info)	((info)->id[0])
 
 /**
- * spi_nor_spimem_xfer_data() - helper function to read/write data to
- *                              flash's memory region
+ * spi_nor_spimem_bounce() - check if a bounce buffer is needed for the data
+ *                           transfer
  * @nor:        pointer to 'struct spi_nor'
  * @op:         pointer to 'struct spi_mem_op' template for transfer
  *
- * Return: number of bytes transferred on success, -errno otherwise
+ * If we have to use the bounce buffer, the data field in @op will be updated.
+ *
+ * Return: true if the bounce buffer is needed, false if not
  */
-static ssize_t spi_nor_spimem_xfer_data(struct spi_nor *nor,
-					struct spi_mem_op *op)
+static bool spi_nor_spimem_bounce(struct spi_nor *nor, struct spi_mem_op *op)
 {
-	bool usebouncebuf = false;
-	void *rdbuf = NULL;
-	const void *buf;
-	int ret;
-
-	if (op->data.dir == SPI_MEM_DATA_IN)
-		buf = op->data.buf.in;
-	else
-		buf = op->data.buf.out;
-
-	if (object_is_on_stack(buf) || !virt_addr_valid(buf))
-		usebouncebuf = true;
-
-	if (usebouncebuf) {
+	/* op->data.buf.in occupies the same memory as op->data.buf.out */
+	if (object_is_on_stack(op->data.buf.in) ||
+	    !virt_addr_valid(op->data.buf.in)) {
 		if (op->data.nbytes > nor->bouncebuf_size)
 			op->data.nbytes = nor->bouncebuf_size;
-
-		if (op->data.dir == SPI_MEM_DATA_IN) {
-			rdbuf = op->data.buf.in;
-			op->data.buf.in = nor->bouncebuf;
-		} else {
-			op->data.buf.out = nor->bouncebuf;
-			memcpy(nor->bouncebuf, buf,
-			       op->data.nbytes);
-		}
+		op->data.buf.in = nor->bouncebuf;
+		return true;
 	}
 
-	ret = spi_mem_adjust_op_size(nor->spimem, op);
-	if (ret)
-		return ret;
+	return false;
+}
 
-	ret = spi_mem_exec_op(nor->spimem, op);
-	if (ret)
-		return ret;
+/**
+ * spi_nor_spimem_exec_op() - execute a memory operation
+ * @nor:        pointer to 'struct spi_nor'
+ * @op:         pointer to 'struct spi_mem_op' template for transfer
+ *
+ * Return: 0 on success, -error otherwise.
+ */
+static int spi_nor_spimem_exec_op(struct spi_nor *nor, struct spi_mem_op *op)
+{
+	int error;
 
-	if (usebouncebuf && op->data.dir == SPI_MEM_DATA_IN)
-		memcpy(rdbuf, nor->bouncebuf, op->data.nbytes);
+	error = spi_mem_adjust_op_size(nor->spimem, op);
+	if (error)
+		return error;
 
-	return op->data.nbytes;
+	return spi_mem_exec_op(nor->spimem, op);
 }
 
 /**
@@ -310,6 +300,9 @@
 			   SPI_MEM_OP_ADDR(nor->addr_width, from, 1),
 			   SPI_MEM_OP_DUMMY(nor->read_dummy, 1),
 			   SPI_MEM_OP_DATA_IN(len, buf, 1));
+	bool usebouncebuf;
+	ssize_t nbytes;
+	int error;
 
 	/* get transfer protocols. */
 	op.cmd.buswidth = spi_nor_get_protocol_inst_nbits(nor->read_proto);
@@ -320,7 +313,22 @@
 	/* convert the dummy cycles to the number of bytes */
 	op.dummy.nbytes = (nor->read_dummy * op.dummy.buswidth) / 8;
 
-	return spi_nor_spimem_xfer_data(nor, &op);
+	usebouncebuf = spi_nor_spimem_bounce(nor, &op);
+
+	if (nor->dirmap.rdesc) {
+		nbytes = spi_mem_dirmap_read(nor->dirmap.rdesc, op.addr.val,
+					     op.data.nbytes, op.data.buf.in);
+	} else {
+		error = spi_nor_spimem_exec_op(nor, &op);
+		if (error)
+			return error;
+		nbytes = op.data.nbytes;
+	}
+
+	if (usebouncebuf && nbytes > 0)
+		memcpy(buf, op.data.buf.in, nbytes);
+
+	return nbytes;
 }
 
 /**
@@ -359,6 +367,8 @@
 			   SPI_MEM_OP_ADDR(nor->addr_width, to, 1),
 			   SPI_MEM_OP_NO_DUMMY,
 			   SPI_MEM_OP_DATA_OUT(len, buf, 1));
+	ssize_t nbytes;
+	int error;
 
 	op.cmd.buswidth = spi_nor_get_protocol_inst_nbits(nor->write_proto);
 	op.addr.buswidth = spi_nor_get_protocol_addr_nbits(nor->write_proto);
@@ -367,7 +377,20 @@
 	if (nor->program_opcode == SPINOR_OP_AAI_WP && nor->sst_write_second)
 		op.addr.nbytes = 0;
 
-	return spi_nor_spimem_xfer_data(nor, &op);
+	if (spi_nor_spimem_bounce(nor, &op))
+		memcpy(nor->bouncebuf, buf, op.data.nbytes);
+
+	if (nor->dirmap.wdesc) {
+		nbytes = spi_mem_dirmap_write(nor->dirmap.wdesc, op.addr.val,
+					      op.data.nbytes, op.data.buf.out);
+	} else {
+		error = spi_nor_spimem_exec_op(nor, &op);
+		if (error)
+			return error;
+		nbytes = op.data.nbytes;
+	}
+
+	return nbytes;
 }
 
 /**
@@ -2081,6 +2104,11 @@
 		.addr_width = 3,					\
 		.flags = SPI_NOR_NO_FR | SPI_S3AN,
 
+static void s25hx_t_default_init(struct spi_nor *nor);
+static struct spi_nor_fixups s25hx_t_fixups = {
+	.default_init = s25hx_t_default_init,
+};
+
 static int
 is25lp256_post_bfpt_fixups(struct spi_nor *nor,
 			   const struct sfdp_parameter_header *bfpt_header,
@@ -2267,6 +2295,12 @@
 			SECT_4K | SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ |
 			SPI_NOR_4B_OPCODES | SPI_NOR_HAS_LOCK | SPI_NOR_HAS_TB)
 	},
+	{
+		"gd55b02ge", INFO(0xc8471c, 0, 64 * 1024, 4096,
+			SECT_4K | SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ |
+			SPI_NOR_4B_OPCODES | SPI_NOR_HAS_LOCK | SPI_NOR_HAS_TB)
+	},
+
 	/* Intel/Numonyx -- xxxs33b */
 	{ "160s33b",  INFO(0x898911, 0, 64 * 1024,  32, 0) },
 	{ "320s33b",  INFO(0x898912, 0, 64 * 1024,  64, 0) },
@@ -2290,6 +2324,9 @@
 			SECT_4K | SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ |
 			SPI_NOR_4B_OPCODES)
 			.fixups = &is25lp256_fixups },
+	{ "is25lp01g",  INFO(0x9d601b, 0, 64 * 1024, 2048,
+			SECT_4K | SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ |
+			SPI_NOR_4B_OPCODES)},
 	{ "is25wp032",  INFO(0x9d7016, 0, 64 * 1024,  64,
 			SECT_4K | SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ) },
 	{ "is25wp064",  INFO(0x9d7017, 0, 64 * 1024, 128,
@@ -2411,6 +2448,43 @@
 	{ "s25fl064l",  INFO(0x016017,      0,  64 * 1024, 128, SECT_4K | SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ | SPI_NOR_4B_OPCODES) },
 	{ "s25fl128l",  INFO(0x016018,      0,  64 * 1024, 256, SECT_4K | SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ | SPI_NOR_4B_OPCODES) },
 	{ "s25fl256l",  INFO(0x016019,      0,  64 * 1024, 512, SECT_4K | SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ | SPI_NOR_4B_OPCODES) },
+	/**
+	 * S25HL/HS-T (Semper Flash with Quad SPI) Family
+	 *
+	 *	 For the faster clock speed than 133MHz (max 166MHz), the Flash
+	 *	 requires 2 dummy cycles before data output in RDID(9fh) and
+	 *	 RDSR(05h) operations. As complex fixups are needed to handle that,
+	 *	 this driver supports up to 133MHz clock speed at this point.
+	 *
+	 *	 The Read SFDP operation is supported up to 50MHz. Since most of the
+	 *	 modern QSPI controllers are assumed to run at faster clock speed
+	 *	 than 50MHz, SFDP parsing is skiped then equivalent setup and some
+	 *	 optimization are done by spi_nor_fixups hooks.
+	 */
+	{ "s25hl256t",	INFO(0x342a19, 0, 256 * 1024, 128,
+				 SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ | USE_CLSR |
+				 SPI_NOR_SKIP_SFDP)
+	  .fixups = &s25hx_t_fixups },
+	{ "s25hl512t",	INFO(0x342a1a, 0, 256 * 1024, 256,
+				 SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ | USE_CLSR |
+				 SPI_NOR_SKIP_SFDP)
+	  .fixups = &s25hx_t_fixups },
+	{ "s25hl01gt",	INFO(0x342a1b, 0, 256 * 1024, 512,
+				 SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ | USE_CLSR |
+				 SPI_NOR_SKIP_SFDP)
+	  .fixups = &s25hx_t_fixups },
+	{ "s25hs256t",	INFO(0x342b19, 0, 256 * 1024, 128,
+				 SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ | USE_CLSR |
+				 SPI_NOR_SKIP_SFDP)
+	  .fixups = &s25hx_t_fixups },
+	{ "s25hs512t",	INFO(0x342b1a, 0, 256 * 1024, 256,
+				 SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ | USE_CLSR |
+				 SPI_NOR_SKIP_SFDP)
+	  .fixups = &s25hx_t_fixups },
+	{ "s25hs01gt",	INFO(0x342b1b, 0, 256 * 1024, 512,
+				 SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ | USE_CLSR |
+				 SPI_NOR_SKIP_SFDP)
+	  .fixups = &s25hx_t_fixups },
 
 	/* SST -- large erase sizes are "overlays", "sectors" are 4K */
 	{ "sst25vf040b", INFO(0xbf258d, 0, 64 * 1024,  8, SECT_4K | SST_WRITE) },
@@ -2550,6 +2624,8 @@
             SECT_4K | SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ |
             SPI_NOR_HAS_LOCK | SPI_NOR_HAS_TB)
     },
+	{ "w25q02jv", INFO(0xef7022, 0, 64 * 1024, 4096, SECT_4K | SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ |
+			SPI_NOR_HAS_LOCK | SPI_NOR_HAS_TB) },	
 	{ "w25m512jv", INFO(0xef7119, 0, 64 * 1024, 1024,
 			SECT_4K | SPI_NOR_QUAD_READ | SPI_NOR_DUAL_READ) },
 
@@ -2996,22 +3072,13 @@
 static int spi_nor_spimem_check_op(struct spi_nor *nor,
 				   struct spi_mem_op *op)
 {
-	/*
-	 * First test with 4 address bytes. The opcode itself might
-	 * be a 3B addressing opcode but we don't care, because
-	 * SPI controller implementation should not check the opcode,
-	 * but just the sequence.
-	 */
-	op->addr.nbytes = 4;
-	if (!spi_mem_supports_op(nor->spimem, op)) {
-		if (nor->mtd.size > SZ_16M)
-			return -ENOTSUPP;
-
-		/* If flash size <= 16MB, 3 address bytes are sufficient */
+	if (nor->mtd.size > SZ_16M)
+		op->addr.nbytes = 4;
+	else
 		op->addr.nbytes = 3;
-		if (!spi_mem_supports_op(nor->spimem, op))
+
+	if (!spi_mem_supports_op(nor->spimem, op))
 			return -ENOTSUPP;
-	}
 
 	return 0;
 }
@@ -3580,6 +3647,385 @@
 	return spi_nor_post_bfpt_fixups(nor, bfpt_header, &bfpt, params);
 }
 
+/**
+ * spansion_read_any_reg() - Read Any Register.
+ * @nor:	pointer to a 'struct spi_nor'
+ * @reg_addr:	register address
+ * @reg_dummy:	number of dummy cycles for register read
+ * @reg_val:	pointer to a buffer where the register value is copied into
+ *
+ * 1 dummy clock cycle is required to read volatile register when CFR3[7:6]=01,
+ * while the spimem takes number of dummy 'bytes'. Since the Flash repeats
+ * outputting the same register contents as long as clock keeps toggling, we can
+ * restore the original register content by reading two bytes
+ *
+ * Return: 0 on success, -errno otherwise.
+ */
+static int spansion_read_any_reg(struct spi_nor *nor, u32 reg_addr,
+				 u8 reg_dummy, u8 *reg_val)
+{
+	u8 read_opcode, read_dummy, dummy_rem;
+	enum spi_nor_protocol read_proto;
+	size_t len;
+	ssize_t ret;
+
+	read_opcode = nor->read_opcode;
+	read_dummy = nor->read_dummy;
+	read_proto = nor->read_proto;
+
+	nor->read_opcode = SPINOR_OP_RDAR;
+	nor->read_dummy = reg_dummy & ~7;
+	nor->read_proto = SNOR_PROTO_1_1_1;
+
+	dummy_rem = reg_dummy - nor->read_dummy;
+	len = dummy_rem ? 2 : 1;
+
+	ret = spi_nor_read_data(nor, reg_addr, len, nor->bouncebuf);
+
+	nor->read_opcode = read_opcode;
+	nor->read_dummy = read_dummy;
+	nor->read_proto = read_proto;
+
+	if (ret == len) {
+		if (dummy_rem)
+			*reg_val = (nor->bouncebuf[0] << dummy_rem) |
+			   (nor->bouncebuf[1] >> (8 - dummy_rem));
+		else
+			*reg_val = nor->bouncebuf[0];
+
+		return 0;
+	}
+
+	return ret < 0 ? ret : -EIO;
+}
+
+/**
+ * spansion_write_any_reg() - Write Any Register.
+ * @nor:	pointer to a 'struct spi_nor'
+ * @reg_addr:	register address
+ * @reg_val:	register value to be written
+ *
+ * Function is for writing volatile registers that will be effective immediately
+ * after the operation (status polling is not needed).
+ *
+ * Return: 0 on success, -errno otherwise.
+ */
+static int spansion_write_any_reg(struct spi_nor *nor, u32 reg_addr, u8 reg_val)
+{
+	u8 program_opcode;
+	enum spi_nor_protocol write_proto;
+	ssize_t ret;
+
+	ret = write_enable(nor);
+	if (ret)
+		return ret;
+
+	program_opcode = nor->program_opcode;
+	write_proto = nor->write_proto;
+
+	nor->program_opcode = SPINOR_OP_WRAR;
+	nor->write_proto = SNOR_PROTO_1_1_1;
+
+	nor->bouncebuf[0] = reg_val;
+	ret = spi_nor_write_data(nor, reg_addr, 1, nor->bouncebuf);
+
+	nor->program_opcode = program_opcode;
+	nor->write_proto = write_proto;
+
+	return ret == 1 ? 0 : (ret < 0 ? ret : -EIO);
+}
+
+/**
+ * spansion_init_sp4k_erase_map() - init erase map for split 4KB sectors
+ * @nor:		pointer to a 'struct spi_nor'
+ * @sector_size:	size of the regular sector (typ. 256KB)
+ * @num_4k_sectors: number of 4KB sectors to split between top and bottom
+ *						(num_4k_sectors/2 at each top and bottom)
+ *
+ * Return: 0 on success, -ENOMEM if devm_kcalloc() fails.
+ */
+static int spansion_init_sp4k_erase_map(struct spi_nor *nor, u32 sector_size,
+					u8 num_4k_sectors)
+{
+	struct spi_nor_erase_map *map = &nor->params.erase_map;
+	struct spi_nor_erase_region *region;
+	u32 sz_4k_region, rem_size;
+	u64 offset;
+
+	region = devm_kcalloc(nor->dev, 5, sizeof(*region), GFP_KERNEL);
+	if (!region)
+		return -ENOMEM;
+
+	map->regions = region;
+	map->uniform_erase_type = 0;
+	sz_4k_region = (num_4k_sectors * SZ_4K) >> 1;
+	rem_size = sector_size - sz_4k_region;
+
+	spi_nor_set_erase_type(&map->erase_type[0], SZ_4K, SPINOR_OP_BE_4K);
+	spi_nor_set_erase_type(&map->erase_type[1], rem_size, SPINOR_OP_SE);
+	spi_nor_set_erase_type(&map->erase_type[2], sector_size, SPINOR_OP_SE);
+
+	region[0].offset = BIT(0);
+	region[0].size = sz_4k_region;
+	offset = region[0].size;
+
+	region[1].offset = offset | BIT(1);
+	region[1].size = rem_size;
+	offset += region[1].size;
+
+	region[2].offset = offset | BIT(2);
+	region[2].size = nor->params.size - (sector_size << 1);
+	offset += region[2].size;
+
+	region[3].offset = offset | BIT(1);
+	region[3].size = rem_size;
+	offset += region[3].size;
+
+	region[4].offset = offset | BIT(0) | SNOR_LAST_REGION;
+	region[4].size = sz_4k_region;
+
+	return 0;
+}
+
+/**
+ * spansion_init_tb4k_erase_map() - init erase map for top/bottom 4KB sectors
+ * @nor:		pointer to a 'struct spi_nor'
+ * @sector_size:	size of the regular sector (typ. 256KB)
+ * @num_4k_sectors: number of 4KB sectors at top or bottom
+ * @top:		true  = 4KB sectors at top
+ *						false = 4KB sectors at bottom
+ *
+ * Return: 0 on success, -ENOMEM if devm_kcalloc() fails.
+ */
+static int spansion_init_tb4k_erase_map(struct spi_nor *nor, u32 sector_size,
+					u8 num_4k_sectors, bool top)
+{
+	struct spi_nor_erase_map *map = &nor->params.erase_map;
+	struct spi_nor_erase_region *region;
+	u32 sz_4k_region, rem_size;
+
+	region = devm_kcalloc(nor->dev, 3, sizeof(*region), GFP_KERNEL);
+	if (!region)
+		return -ENOMEM;
+
+	map->regions = region;
+	map->uniform_erase_type = 0;
+	sz_4k_region = num_4k_sectors * SZ_4K;
+	rem_size = sector_size - sz_4k_region;
+
+	spi_nor_set_erase_type(&map->erase_type[0], SZ_4K, SPINOR_OP_BE_4K);
+	spi_nor_set_erase_type(&map->erase_type[1], rem_size, SPINOR_OP_SE);
+	spi_nor_set_erase_type(&map->erase_type[2], sector_size, SPINOR_OP_SE);
+
+	if (top) {
+		region[0].offset = BIT(2);
+		region[0].size = nor->params.size - sector_size;
+
+		region[1].offset = region[0].size | BIT(1);
+		region[1].size = rem_size;
+
+		region[2].offset = (region[0].size + region[1].size) | BIT(0);
+		region[2].size = sz_4k_region;
+	} else {
+		region[0].offset = BIT(0);
+		region[0].size = sz_4k_region;
+
+		region[1].offset = sz_4k_region | BIT(1);
+		region[1].size = rem_size;
+
+		region[2].offset = nor->info->sector_size | BIT(2);
+		region[2].size = nor->params.size - sector_size;
+	}
+	region[2].offset |= SNOR_LAST_REGION;
+
+	return 0;
+}
+
+/**
+ * spansion_quad_enable_volatile() - enable Quad I/O mode in volatile register.
+ * @nor:		pointer to a 'struct spi_nor'
+ * @reg_addr_base:	base address of register (can be >0 in multi-die parts)
+ * @reg_dummy:		number of dummy cycles for register read
+ *
+ * It is recommended to update volatile registers in the field application due
+ * to a risk of the non-volatile registers corruption by power interrupt. This
+ * function sets Quad Enable bit in CFR1 volatile. If users set the Quad Enable
+ * bit in the CFR1 non-volatile in advance (typically by a Flash programmer
+ * before mounting Flash on PCB), the Quad Enable bit in the CFR1 volatile is
+ * also set during Flash power-up.
+ *
+ * Return: 0 on success, -errno otherwise.
+ */
+static int spansion_quad_enable_volatile(struct spi_nor *nor, u32 reg_addr_base,
+					 u8 reg_dummy)
+{
+	u32 reg_addr = reg_addr_base + SPINOR_REG_ADDR_CFR1V;
+	u8 cfr1v, cfr1v_written;
+	int ret;
+
+	/* Check current Quad Enable bit value. */
+	ret = spansion_read_any_reg(nor, reg_addr, reg_dummy, &cfr1v);
+	if (ret)
+		return ret;
+	if (cfr1v & CFR1_QUAD_EN)
+		return 0;
+
+	/* Update the Quad Enable bit. */
+	cfr1v |= CFR1_QUAD_EN;
+
+	ret = spansion_write_any_reg(nor, reg_addr, cfr1v);
+	if (ret)
+		return ret;
+
+	cfr1v_written = cfr1v;
+
+	/* Read back and check it. */
+	ret = spansion_read_any_reg(nor, reg_addr, reg_dummy, &cfr1v);
+	if (ret)
+		return ret;
+
+	if (cfr1v != cfr1v_written) {
+		dev_dbg(nor->dev, "CFR1: Read back test failed\n");
+		return -EIO;
+	}
+
+	return 0;
+}
+
+/**
+ * s25hx_t_set_read_settings() - read settings for s25hx-t family
+ * @params: pointer to the 'struct spi_nor_flash_parameter'
+ *
+ * Function assumes the opcodes will be converted to 4B opcodes
+ */
+static void s25hx_t_set_read_settings(struct spi_nor_flash_parameter *params)
+{
+	struct spi_nor_read_command *read;
+
+	/* Fast Read 4B requires mode cycles */
+	read = &params->reads[SNOR_CMD_READ_FAST];
+	read->num_mode_clocks = 8;
+
+	/* Dual Output Read is not supported */
+	params->hwcaps.mask &= ~SNOR_HWCAPS_READ_1_1_2;
+
+	/* Add Dual I/O Read */
+	params->hwcaps.mask |= SNOR_HWCAPS_READ_1_2_2;
+	read = &params->reads[SNOR_CMD_READ_1_2_2];
+	read->num_mode_clocks = 4;
+	read->num_wait_states = 8;
+	read->opcode = SPINOR_OP_READ_1_2_2;
+	read->proto = SNOR_PROTO_1_2_2;
+
+	/* Add Quad I/O Read */
+	params->hwcaps.mask |= SNOR_HWCAPS_READ_1_4_4;
+	read = &params->reads[SNOR_CMD_READ_1_4_4];
+	read->num_mode_clocks = 2;
+	read->num_wait_states = 8;
+	read->opcode = SPINOR_OP_READ_1_4_4;
+	read->proto = SNOR_PROTO_1_4_4;
+}
+
+static int spi_nor_default_setup(struct spi_nor *nor,
+				 const struct spi_nor_hwcaps *hwcaps);
+
+/**
+ * s25hx_t_setup() - configure s25hx_t device.
+ * @nor:	pointer to a 'struct spi_nor'
+ * @hwcaps: pointer to a 'struct spi_nor_hwcaps'
+ *
+ * Read, Program, and Erase settings in place of SFDP
+ *
+ * Return: 0 on success, -errno otherwise.
+ */
+static int s25hx_t_setup(struct spi_nor *nor,
+			 const struct spi_nor_hwcaps *hwcaps)
+{
+	int err;
+	u8 cfr3_written, reg;
+
+	s25hx_t_set_read_settings(&nor->params);
+
+	/* Address mode affects Read/Write Any Register operations */
+	nor->addr_width = 4;
+	err = macronix_set_4byte(nor, true);
+	if (err)
+		return err;
+
+	/**
+	 * Optimal CFR3V settings
+	 *	 CFR3[7:6] = 01: RDAR for v-regs works ~133MHz with 1 dummy cycle
+	 *	 CFR3[5] = 1: Erase operation is skipped on already erased sectors
+	 *	 CFR3[4] = 1: 512 byte page size (better throughput than 256 byte)
+	 *	 CFR3[3] = x: Read-Only for volatile register
+	 *	 CFR3[2] = 0: CLSR(30h) is enabled (default)
+	 *	 CFR3[1] = 0: Reserved
+	 *	 CFR3[0] = 0: Legacy SW reset is disabled (default)
+	 *
+	 * At this point, we don't know the volatile register latency setting in
+	 * CFR3[7:6]. Therefore, just write the optimal settings to CFR3 instead
+	 * of Read-Modify-Write.
+	 */
+	cfr3_written = CFR3_VREG_LTCY_01 | CFR3_BLANK_CHECK_EN |
+			   CFR3_512B_PAGE_SIZE;
+
+	err = spansion_write_any_reg(nor, SPINOR_REG_ADDR_CFR3V, cfr3_written);
+	if (err)
+		return err;
+
+	/* Read back CFR3V with 1 dummy cycle */
+	err = spansion_read_any_reg(nor, SPINOR_REG_ADDR_CFR3V, 1, &reg);
+	if (err)
+		return err;
+	if ((reg & ~CFR3_UNIFORM_SECTORS) != cfr3_written)
+		return -EIO;
+
+	/* Update page size */
+	nor->page_size = 512;
+	nor->mtd.writebufsize = nor->page_size;
+
+	/**
+	 * The s25hx_t family has transparent ECC. To preserve ECC enabled,
+	 * multi-pass programming within the same 16-byte ECC data unit needs
+	 * to be avoided. Setting writesize to the multiples of 16 and removing
+	 * the MTD_BIT_WRITEABLE flags in mtd_info let JFFS2 enable write-
+	 * buffering that prevents multi-pass programming
+	 * (CONFIG_JFFS2_FS_WRITEBUFFER needs to be enabled). To achieve the
+	 * best write throughput, assign 512-byte page size to writesize.
+	 */
+	nor->mtd.writesize = nor->page_size;
+	nor->mtd.flags = MTD_CAP_NORFLASH & ~MTD_BIT_WRITEABLE;
+
+	/* Uniform Sectors: use erase map set in spi_nor_info_init_params() */
+	if (reg & CFR3_UNIFORM_SECTORS)
+		return spi_nor_default_setup(nor, hwcaps);
+
+	/* Hybrid Sectors: check CFR1 bits */
+	err = spansion_read_any_reg(nor, SPINOR_REG_ADDR_CFR1V, 1, &reg);
+	if (err)
+		return err;
+
+	if (reg & CFR1_SPLIT_4K_SECTORS)
+		err = spansion_init_sp4k_erase_map(nor, SZ_256K, 32);
+	else if (reg & CFR1_TOP_4K_SECTORS)
+		err = spansion_init_tb4k_erase_map(nor, SZ_256K, 32, true);
+	else
+		err = spansion_init_tb4k_erase_map(nor, SZ_256K, 32, false);
+
+	return err ? err : spi_nor_default_setup(nor, hwcaps);
+}
+
+static int s25hx_t_quad_enable(struct spi_nor *nor)
+{
+	return spansion_quad_enable_volatile(nor, 0, 1);
+}
+
+static void s25hx_t_default_init(struct spi_nor *nor)
+{
+	nor->params.setup = s25hx_t_setup;
+	nor->params.quad_enable = s25hx_t_quad_enable;
+}
+
 #define SMPT_CMD_ADDRESS_LEN_MASK		GENMASK(23, 22)
 #define SMPT_CMD_ADDRESS_LEN_0			(0x0UL << 22)
 #define SMPT_CMD_ADDRESS_LEN_3			(0x1UL << 22)
@@ -4477,6 +4923,7 @@
 	/* Init flash parameters based on MFR */
 	switch (JEDEC_MFR(nor->info)) {
 	case SNOR_MFR_MACRONIX:
+	case SNOR_MFR_ISSI:
 		macronix_set_default_init(nor);
 		break;
 
@@ -4486,6 +4933,7 @@
 		break;
 
 	case SNOR_MFR_WINBOND:
+	case SNOR_MFR_GIGADEVICE:
 		winbond_set_default_init(nor);
 		break;
 
@@ -4511,10 +4959,11 @@
 
 	memcpy(&sfdp_params, &nor->params, sizeof(sfdp_params));
 
-	if (spi_nor_parse_sfdp(nor, &nor->params)) {
-		memcpy(&nor->params, &sfdp_params, sizeof(nor->params));
+	if (spi_nor_parse_sfdp(nor, &sfdp_params)) {
 		nor->addr_width = 0;
 		nor->flags &= ~SNOR_F_4B_OPCODES;
+	} else {
+		memcpy(&nor->params, &sfdp_params, sizeof(nor->params));
 	}
 }
 
@@ -5044,6 +5493,58 @@
 }
 EXPORT_SYMBOL_GPL(spi_nor_scan);
 
+static int spi_nor_create_read_dirmap(struct spi_nor *nor)
+{
+	struct spi_mem_dirmap_info info = {
+		.op_tmpl = SPI_MEM_OP(SPI_MEM_OP_CMD(nor->read_opcode, 1),
+				      SPI_MEM_OP_ADDR(nor->addr_width, 0, 1),
+				      SPI_MEM_OP_DUMMY(nor->read_dummy, 1),
+				      SPI_MEM_OP_DATA_IN(0, NULL, 1)),
+		.offset = 0,
+		.length = nor->mtd.size,
+	};
+	struct spi_mem_op *op = &info.op_tmpl;
+
+	/* get transfer protocols. */
+	op->cmd.buswidth = spi_nor_get_protocol_inst_nbits(nor->read_proto);
+	op->addr.buswidth = spi_nor_get_protocol_addr_nbits(nor->read_proto);
+	op->dummy.buswidth = op->addr.buswidth;
+	op->data.buswidth = spi_nor_get_protocol_data_nbits(nor->read_proto);
+
+	/* convert the dummy cycles to the number of bytes */
+	op->dummy.nbytes = (nor->read_dummy * op->dummy.buswidth) / 8;
+
+	nor->dirmap.rdesc = devm_spi_mem_dirmap_create(nor->dev, nor->spimem,
+						       &info);
+	return PTR_ERR_OR_ZERO(nor->dirmap.rdesc);
+}
+
+static int spi_nor_create_write_dirmap(struct spi_nor *nor)
+{
+	struct spi_mem_dirmap_info info = {
+		.op_tmpl = SPI_MEM_OP(SPI_MEM_OP_CMD(nor->program_opcode, 1),
+				      SPI_MEM_OP_ADDR(nor->addr_width, 0, 1),
+				      SPI_MEM_OP_NO_DUMMY,
+				      SPI_MEM_OP_DATA_OUT(0, NULL, 1)),
+		.offset = 0,
+		.length = nor->mtd.size,
+	};
+	struct spi_mem_op *op = &info.op_tmpl;
+
+	/* get transfer protocols. */
+	op->cmd.buswidth = spi_nor_get_protocol_inst_nbits(nor->write_proto);
+	op->addr.buswidth = spi_nor_get_protocol_addr_nbits(nor->write_proto);
+	op->dummy.buswidth = op->addr.buswidth;
+	op->data.buswidth = spi_nor_get_protocol_data_nbits(nor->write_proto);
+
+	if (nor->program_opcode == SPINOR_OP_AAI_WP && nor->sst_write_second)
+		op->addr.nbytes = 0;
+
+	nor->dirmap.wdesc = devm_spi_mem_dirmap_create(nor->dev, nor->spimem,
+						       &info);
+	return PTR_ERR_OR_ZERO(nor->dirmap.wdesc);
+}
+
 static int spi_nor_probe(struct spi_mem *spimem)
 {
 	struct spi_device *spi = spimem->spi;
@@ -5105,6 +5606,14 @@
 			return -ENOMEM;
 	}
 
+	ret = spi_nor_create_read_dirmap(nor);
+	if (ret)
+		return ret;
+
+	ret = spi_nor_create_write_dirmap(nor);
+	if (ret)
+		return ret;
+
 	return mtd_device_register(&nor->mtd, data ? data->parts : NULL,
 				   data ? data->nr_parts : 0);
 }
diff -Naur linux_org/drivers/watchdog/aspeed_wdt.c linux/drivers/watchdog/aspeed_wdt.c
--- linux_org/drivers/watchdog/aspeed_wdt.c	2021-05-11 16:20:48.674830844 +0800
+++ linux/drivers/watchdog/aspeed_wdt.c	2021-05-11 09:19:53.000000000 +0800
@@ -472,18 +472,18 @@
 		u32 reg = readl(wdt->base + ((*current_wdt_no - 1)*OFFSET_CALCULATOR) + WDT_RESET_WIDTH);
 
 		reg &= config->ext_pulse_width_mask;
-		if (of_property_read_bool(np, "aspeed,ext-push-pull"))
-			reg |= WDT_PUSH_PULL_MAGIC;
+		if (of_property_read_bool(np, "aspeed,ext-active-high"))
+			reg |= WDT_ACTIVE_HIGH_MAGIC;
 		else
-			reg |= WDT_OPEN_DRAIN_MAGIC;
+			reg |= WDT_ACTIVE_LOW_MAGIC;
 
 		writel(reg, wdt->base + ((*current_wdt_no - 1)*OFFSET_CALCULATOR)  + WDT_RESET_WIDTH);
 
 		reg &= config->ext_pulse_width_mask;
-		if (of_property_read_bool(np, "aspeed,ext-active-high"))
-			reg |= WDT_ACTIVE_HIGH_MAGIC;
+		if (of_property_read_bool(np, "aspeed,ext-push-pull"))
+			reg |= WDT_PUSH_PULL_MAGIC;
 		else
-			reg |= WDT_ACTIVE_LOW_MAGIC;
+			reg |= WDT_OPEN_DRAIN_MAGIC;
 
 		writel(reg, wdt->base + ((*current_wdt_no - 1)*OFFSET_CALCULATOR) + WDT_RESET_WIDTH);
 	}
diff -Naur linux_org/include/linux/mtd/spi-nor.h linux/include/linux/mtd/spi-nor.h
--- linux_org/include/linux/mtd/spi-nor.h	2020-12-21 20:27:07.000000000 +0800
+++ linux/include/linux/mtd/spi-nor.h	2021-05-11 09:21:33.000000000 +0800
@@ -26,6 +26,7 @@
 #define SNOR_MFR_SPANSION	CFI_MFR_AMD
 #define SNOR_MFR_SST		CFI_MFR_SST
 #define SNOR_MFR_WINBOND	0xef /* Also used by some Spansion */
+#define SNOR_MFR_ISSI		0x9d
 
 /*
  * Note on opcode nomenclature: some opcodes have a format like
@@ -115,6 +116,20 @@
 /* Used for Spansion flashes only. */
 #define SPINOR_OP_BRWR		0x17	/* Bank register write */
 #define SPINOR_OP_CLSR		0x30	/* Clear status register 1 */
+#define SPINOR_OP_RDAR		0x65	/* Read Any Register */
+#define SPINOR_OP_WRAR		0x71	/* Write Any Register */
+
+#define SPINOR_REG_ADDR_CFR1V	0x00800002	/* Config Reg 1 volatile */
+#define SPINOR_REG_ADDR_CFR3V	0x00800004	/* Config Reg 3 volatile */
+
+#define CFR3_VREG_LTCY_01	BIT(6)	/* 1 dummy for v-reg read at 133MHz */
+#define CFR3_BLANK_CHECK_EN	BIT(5)	/* Skip erase on erased sectors */
+#define CFR3_512B_PAGE_SIZE	BIT(4)	/* 512 byte page size */
+#define CFR3_UNIFORM_SECTORS	BIT(3)	/* Uniform sector is selected */
+
+#define CFR1_SPLIT_4K_SECTORS	BIT(6)	/* 4KB sectors at top and bottom */
+#define CFR1_TOP_4K_SECTORS	BIT(2)	/* 4KB sectors at top */
+#define CFR1_QUAD_EN		BIT(1)	/* Quad Enable */
 
 /* Used for Micron flashes only. */
 #define SPINOR_OP_RD_EVCR      0x65    /* Read EVCR register */
@@ -566,6 +581,7 @@
  *                      The structure includes legacy flash parameters and
  *                      settings that can be overwritten by the spi_nor_fixups
  *                      hooks, or dynamically when parsing the SFDP tables.
+ * @dirmap:		pointers to struct spi_mem_dirmap_desc for reads/writes.
  * @priv:		the private data
  */
 struct spi_nor {
@@ -602,6 +618,11 @@
 	int (*clear_sr_bp)(struct spi_nor *nor);
 	struct spi_nor_flash_parameter params;
 
+	struct {
+		struct spi_mem_dirmap_desc *rdesc;
+		struct spi_mem_dirmap_desc *wdesc;
+	} dirmap;
+
 	void *priv;
 };
 
